{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UFResearchComputing/gatorAI_summer_camp_2024/blob/main/01_full_of_emotion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><img src=\"images/gator_ai_camp_2024_logo_200.png\" align=\"right\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KhpJb5VI79P"
      },
      "source": [
        "# Gator AI Summer Camp 2024\n",
        "\n",
        "In this first notebook, we're going to use Python to create a deep learning model that can take images of faces and output the emotion being expressed.\n",
        "\n",
        "The dataset we're going to use is the FER-2013 dataset, which contains 35,887 grayscale images of faces. Each image is 48x48 pixels and is labeled with one of seven emotions: anger, disgust, fear, happiness, sadness, surprise, or neutral. The dataset and more information can be found [on Kaggle](https://www.kaggle.com/datasets/msambare/fer2013/data).\n",
        "\n",
        "**Note:** One issue with the dataset is that it has relatively few images in the disgust category, so we drop that category for this exercise.\n",
        "\n",
        "To build our model, we'll use the Keras deep learning library, which provides a high-level interface for building and training neural networks. We'll start by loading the dataset and exploring the images, then we'll build and train a convolutional neural network (CNN) to classify the emotions in the images.\n",
        "\n",
        "**Before you get started, make sure to select a Runtime with a GPU!** <img src='images/colab_change_runtime_type.png' align='right' width='50%' alt='Image of the Runtime menu options in Google Colab'>\n",
        "* Go to the **\"Runtime\"** menu\n",
        "* Select **\"Change runtime type\"**\n",
        "* Select **\"T4 GPU\"** and click **\"Save\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVz8_6AYI79Q",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from functools import reduce\n",
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "# Import the libraries for CNNs\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Import the libraries for the evaluation\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hVyqZVn3KLEY"
      },
      "outputs": [],
      "source": [
        "# Download the data from Kaggle and unzip into data directory\n",
        "# Lines that start with ! are run as BASH or command line code, not Python\n",
        "!kaggle datasets download -d msambare/fer2013\n",
        "!mkdir data\n",
        "!unzip fer2013.zip -d data/\n",
        "\n",
        "#Delete the disgust folders as there are so few examples in that cetegory.\n",
        "!rm -rf data/train/disgust\n",
        "!rm -rf data/test/disgust"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ioyd0sAI79R",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def load_display_data(path, batch_size=32, shape=(80, 80, 1), show_pictures=True, show_histogram=True, augment=False, balance_classes=False):\n",
        "    '''Takes a path, batch size, target shape for images and optionally whether to show sample images, augment data, and balance classes.\n",
        "       Returns training and testing datasets\n",
        "    '''\n",
        "    print(\"***********************************************************************\")\n",
        "    print(\"Load data:\")\n",
        "    print(f\"  - Loading the dataset from: {path}.\")\n",
        "    print(f\"  - Using a batch size of: {batch_size}.\")\n",
        "    print(f\"  - Resizing input images to: {shape}.\")\n",
        "    print(f\"  - Data augmentation: {augment}.\")\n",
        "    print(f\"  - Balance classes: {balance_classes}.\")\n",
        "    print(\"***********************************************************************\")\n",
        "\n",
        "    # Define the directory path\n",
        "    directory_path = path\n",
        "\n",
        "    # Define the batch size\n",
        "    batch_size = batch_size\n",
        "\n",
        "    # Define the image size using the 1st 2 elements of the shape parameter\n",
        "    # We don't need the number of channels here, just the dimensions to use\n",
        "    image_size = shape[:2]\n",
        "\n",
        "    # Create the data augmentation pipeline if augmentation is enabled\n",
        "    data_augmentation = tf.keras.Sequential([\n",
        "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "        tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "        tf.keras.layers.experimental.preprocessing.RandomContrast(0.1)\n",
        "    ]) if augment else None\n",
        "\n",
        "    # Load the dataset\n",
        "    X_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        os.path.join(directory_path, 'train'),\n",
        "        batch_size=batch_size,\n",
        "        image_size=image_size,\n",
        "        labels='inferred',\n",
        "        label_mode='int',\n",
        "        color_mode='grayscale'\n",
        "    )\n",
        "\n",
        "    X_val = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        os.path.join(directory_path, 'test'),\n",
        "        batch_size=batch_size,\n",
        "        image_size=image_size,\n",
        "        labels='inferred',\n",
        "        label_mode='int',\n",
        "        color_mode='grayscale'\n",
        "    )\n",
        "\n",
        "    # Store class names before transforming the dataset\n",
        "    class_names = X_train.class_names\n",
        "\n",
        "\n",
        "    # Apply data augmentation to the training dataset if enabled\n",
        "    if augment:\n",
        "        X_train = X_train.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "\n",
        "    if show_pictures:\n",
        "        print(class_names)\n",
        "\n",
        "        # Display up to 3 images from each of the categories\n",
        "        class_images_dict = {class_name: [] for class_name in class_names}\n",
        "\n",
        "        # Collect images for each class\n",
        "        for images, labels in X_train:\n",
        "            images = images.numpy()\n",
        "            labels = labels.numpy()\n",
        "\n",
        "            for i, class_name in enumerate(class_names):\n",
        "                if len(class_images_dict[class_name]) < 3:\n",
        "                    # Filter images of the current class\n",
        "                    class_images = images[labels == i]\n",
        "                    class_images_dict[class_name].extend(class_images[:3 - len(class_images_dict[class_name])])\n",
        "\n",
        "            # Break if we have collected enough images for all classes\n",
        "            if all(len(imgs) >= 3 for imgs in class_images_dict.values()):\n",
        "                break\n",
        "\n",
        "        # Display the collected images\n",
        "        for class_name, class_images in class_images_dict.items():\n",
        "            fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
        "            fig.subplots_adjust(wspace=0, hspace=30)  # Adjust the space between subplots\n",
        "\n",
        "            for j in range(len(class_images)):\n",
        "                ax = axs[j]\n",
        "                ax.imshow(class_images[j].astype(\"uint8\"), cmap='gray')\n",
        "                ax.set_title(class_name)\n",
        "                ax.axis(\"off\")\n",
        "                ax.set_xticklabels([])\n",
        "                ax.set_yticklabels([])\n",
        "                ax.set_aspect('equal')\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "    train_labels = []\n",
        "\n",
        "    if show_histogram:\n",
        "        # Collect all labels for training and validation datasets\n",
        "        for images, labels in X_train:\n",
        "            train_labels.extend(labels.numpy())\n",
        "\n",
        "        val_labels = []\n",
        "        for images, labels in X_val:\n",
        "            val_labels.extend(labels.numpy())\n",
        "\n",
        "        # Display the class distribution for the entire dataset\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(\"Dataset\")\n",
        "        # Title for the total dataset\n",
        "        plt.hist(train_labels + val_labels, bins=np.arange(len(class_names) + 1) - 0.5, edgecolor='black')\n",
        "        plt.xticks(range(len(class_names)), labels=class_names, rotation=45)\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(\"Training\")\n",
        "        plt.hist(train_labels, bins=np.arange(len(class_names) + 1) - 0.5, edgecolor='black')\n",
        "        plt.xticks(range(len(class_names)), labels=class_names, rotation=45)\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(\"Validation\")\n",
        "        plt.hist(val_labels, bins=np.arange(len(class_names) + 1) - 0.5, edgecolor='black')\n",
        "        plt.xticks(range(len(class_names)), labels=class_names, rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    if balance_classes:\n",
        "        class_weights = class_weight.compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=np.unique(train_labels),\n",
        "            y=train_labels\n",
        "        )\n",
        "        class_weights = tf.constant(list(class_weights))  # Convert to TensorFlow constant\n",
        "\n",
        "        # Apply class weights to the training dataset using tf.gather\n",
        "        X_train = X_train.map(lambda img, label: (img, label, tf.gather(class_weights, tf.cast(label, tf.int32))))\n",
        "\n",
        "        # (If needed, you could also adjust the validation set weights, but typically not necessary)\n",
        "        # X_val = X_val.map(lambda img, label: (img, label, tf.gather(class_weights, tf.cast(label, tf.int32))))\n",
        "\n",
        "    return X_train, X_val\n",
        "\n",
        "data_path = 'data/'\n",
        "\n",
        "X_train, X_val = load_display_data(data_path, batch_size=32, shape=(80, 80, 1), show_pictures=True, show_histogram=True, augment=True, balance_classes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnhLgZuKI79S",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the CNN model architecture\n",
        "\n",
        "def create_model(input_shape, num_classes, padding='same', activation='relu', dropout_rate=0.2):\n",
        "    '''Takes the input shape and number of classes and returns a CNN model'''\n",
        "    print(\"***********************************************************************\")\n",
        "    print(\"Create model:\")\n",
        "    print(f\"  - Input shape: {input_shape}.\")\n",
        "    print(f\"  - Number of classes: {num_classes}.\")\n",
        "    print(\"***********************************************************************\")\n",
        "    # Create the model\n",
        "    model = Sequential([\n",
        "        Conv2D(16, 3, padding=padding, activation=activation, input_shape=input_shape),\n",
        "        MaxPooling2D(),\n",
        "        Dropout(dropout_rate),\n",
        "        Conv2D(32, 3, padding=padding, activation=activation),\n",
        "        MaxPooling2D(),\n",
        "        Dropout(dropout_rate),\n",
        "        Conv2D(64, 3, padding=padding, activation=activation),\n",
        "        MaxPooling2D(),\n",
        "        Dropout(dropout_rate),\n",
        "        Flatten(),\n",
        "        Dense(128, activation=activation),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    # Visualize the model\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define our instance of the model\n",
        "\n",
        "input_shape = (80, 80, 1)\n",
        "num_classes = 6\n",
        "\n",
        "model = create_model(input_shape, num_classes, padding='same', activation='relu')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjDb-jtzI79S",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t07Yf2EcI79S",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, validation_data=X_val, epochs=30, callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o4e6FcuI79T",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "print(\"***********************************************************************\")\n",
        "print(\"Accuracy and Loss per Epoch:\")\n",
        "print(\"***********************************************************************\")\n",
        "loss, accuracy = model.evaluate(X_val)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
        "\n",
        "# Plot the training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.title(\"Accuracy\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "# Define a function to plot the confusion matrix\n",
        "def plot_confusion_matrix(model, dataset):\n",
        "    print(\"***********************************************************************\")\n",
        "    print(\"Confusion matrix:\")\n",
        "    print(\"***********************************************************************\")\n",
        "\n",
        "    # Get the true labels\n",
        "    y_true = []\n",
        "    for images, labels in dataset:\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "    # Get the predicted labels\n",
        "    y_pred = model.predict(dataset)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Get the class names\n",
        "    class_names = dataset.class_names\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion matrix')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.xticks(range(len(class_names)), labels=class_names, rotation=45)\n",
        "    plt.yticks(range(len(class_names)), labels=class_names)\n",
        "\n",
        "    # Annotate each cell with the numeric value\n",
        "    thresh = cm.max() / 2\n",
        "    for i in range(len(class_names)):\n",
        "        for j in range(len(class_names)):\n",
        "            plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage (assuming X_val is your validation dataset)\n",
        "plot_confusion_matrix(model, X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHaZCvxpRsga"
      },
      "source": [
        "## Save our model\n",
        "\n",
        "Now that we've trained our model, we can save it for the next steps where we will want to use the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdDCs9OlI79T"
      },
      "outputs": [],
      "source": [
        "model.save('emotion_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nldt4Ez1UIjl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
